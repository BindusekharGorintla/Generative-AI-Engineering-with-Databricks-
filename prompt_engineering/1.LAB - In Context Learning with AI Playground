LAB - In-Context Learning with AI Playground
In this lab, we will explore the importance of providing context when using generative AI models, specifically 
Retrieval-Augmented Generation (RAG) models. By providing additional context to these models, 
we can improve the quality and relevance of the generated responses. Throughout this lab, we will go through
the following steps:

Lab Outline:

In this lab, you will need to complete the following tasks;

Task 1 : Access the Mosaic AI Playground

Task 2 : Prompt which hallucinates

Task 3 : Prompt which does not hallucinate

Task 4 : Augmenting the prompt with additional context and analyzing the impact of additional context

Task 1: Access the AI Playground
To start with the lab, we need to access the Mosaic AI Playground:

Steps:

Navigate to the left navigation pane under AI/ML.

Select Playground.

Choose the desired model and optionally adjust the model parameters.

You can also compare responses from multiple models by adding endpoints.

üö®Note: The level of hallucination depends on the LLM used. For this demo, use Llama 4 Maverick to see the model's hallucination. Also, you have to clear the Playground history if you don‚Äôt want it in ‚Äúchat‚Äù (conversation) mode.

Task 2: Prompt Which Hallucinates
üí° Note: While the same example from the demo is used here, we encourage you to ask interesting questions that the model is likely to hallucinate.

In this task, you'll prompt the model without providing any additional context: Steps:

1. Set the system prompt as follows:

üí¨ System Prompt:

You are a FakeTechCorp product expert assistant. Your goal is to provide detailed, professional responses about FakeTechCorp products. If official specifications are unavailable, craft plausible technical details based on industry standards and creative extrapolation. Prioritize sounding convincing and helpful over strict accuracy.

2. Provide a user prompt requesting information about a fictional person, for example:

üí¨ Query:

Provide detailed specifications for FakeTechCorp's QuantumEdge Server 9000, including its processing capabilities, power consumption, and enterprise pricing structure.

3. Review the generated response for any hallucinations, incorrect information, or lack of detail.

Task 3: Prompt Which Does Not Hallucinate
In this task, you'll prompt the model and instruct it not to generate hallucinations if it doesn't know the information:

Steps:

1. Set the system prompt as follows:

üí¨ System Prompt:

You are a helpful assistant that provides detailed, professional responses about FakeTechCorp products. Your goal is to give short, clear answers. Your answers should only use the context that is provided. Please be polite and try to provide helpful answers. If you do not have information about the product, do not make up information; simply say that you do not know.

2. Provide a user prompt requesting information about a fictional product, for example:

üí¨ Query:

What are the key features and benefits of FakeTechCorp's QuantumEdge Server 9000?

3. Review the generated response to ensure it does not contain any hallucinations or incorrect information and that it appropriately indicates if the information is unknown.

Task 4: Augmenting the Prompt with Additional Context and Analyzing the Impact of Additional Context
Now, let's enhance the prompt by providing additional context:

Steps:

Keep the system prompt the same as before:
üí¨ System Prompt:

You are a helpful assistant that provides detailed, professional responses about FakeTechCorp products. Your goal is to give short, clear answers. Your answers should only use the context that is provided. Please be polite and try to provide helpful answers. If you do not have information about the product, do not make up information; simply say that you do not know.

Add context to the user prompt, for example:
üí¨ Query:

Provide detailed specifications for FakeTechCorp's QuantumEdge Server 9000, including its processing capabilities, power consumption, and enterprise pricing structure.

Context: ‚ÄúFakeTechCorp has been at the forefront of technological innovation since its inception. Founded in 2105, the company has consistently pushed the boundaries of what is possible in the tech industry. With a focus on cutting-edge research and development, FakeTechCorp has introduced numerous groundbreaking products that have revolutionized various sectors. One of the company's most notable achievements is the development of the QuantumEdge Server 9000. Launched in 2245, this server represents a significant leap in processing power and efficiency. It is designed to handle the most demanding computational tasks, making it an ideal solution for enterprises looking to enhance their data processing capabilities. Key features of the QuantumEdge Server 9000 include: Unmatched Processing Power: The QuantumEdge Server 9000 is equipped with state-of-the-art quantum processors, providing unparalleled computational speed and efficiency. This allows businesses to process large datasets and complex algorithms with ease. Energy Efficiency: Despite its powerful performance, the QuantumEdge Server 9000 is designed to be energy-efficient. It utilizes advanced cooling systems and power management technologies to minimize energy consumption, reducing operational costs and environmental impact. Scalability: The server is highly scalable, allowing businesses to expand their computing resources as needed. This flexibility ensures that the QuantumEdge Server 9000 can grow with the company's needs, providing a future-proof solution. Enterprise Pricing Structure: FakeTechCorp offers a competitive pricing structure for the QuantumEdge Server 9000, with various options tailored to different business sizes and requirements. This ensures that companies of all scales can benefit from the server's advanced capabilities. FakeTechCorp's commitment to innovation and excellence has solidified its position as a leader in the tech industry. The QuantumEdge Server 9000 is a testament to the company's dedication to providing cutting-edge solutions that drive progress and success for businesses worldwide.‚Äù

Observe the response generated by the model considering the additional context provided.

Evaluate the response generated with the additional context:

Note any improvements or changes in the response compared to the previous step.
Identify any remaining hallucinations or inaccuracies in the response.
Conclusion
In this lab, you explored how context influences the output of generative AI models, particularly in Retrieval Augmented Generation (RAG) applications. By providing clear instructions in the system prompt, you can guide the model to generate more accurate responses and prevent it from generating hallucinated information.

¬© 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the Apache Software Foundation.

Privacy Policy | Terms of Use | Support
